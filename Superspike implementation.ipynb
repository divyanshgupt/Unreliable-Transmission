{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Superspike implementation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ddG8pHV0kwc"
      },
      "source": [
        "Link to paper: [Zenke, Ganguli - 2018](https://direct.mit.edu/neco/article/30/6/1514-1541/8378)\n",
        "\n",
        "Zenke's [Tutorial](https://github.com/fzenke/spytorch) on Surrogate Gradient Descent using PyTorch.\n",
        "\n",
        "To Implement:\n",
        "1. LIF Neurons (maybe a class of such neurons)\n",
        "2. Fast Sigmoid Function\n",
        "\n",
        "Question:\n",
        "1. How to implement spiking neural network in pytorch? \n",
        "  * use RNNs as Zenke suggests in his tutorial?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPL18elCNSBW"
      },
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A42hX2QOHrHl"
      },
      "source": [
        "dtype = torch.float\n",
        "device = torch.device(\"cpu\")\n",
        "\n",
        "# Uncomment the line below to run on GPU\n",
        "# device = torch.device(\"cuda:0\") "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Y-EjYFuIet1"
      },
      "source": [
        "### Network Architecture\n",
        "\n",
        "3 layer feed-forward neural network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GuJ0JQZbIoBS"
      },
      "source": [
        "nb_inputs  = 100\n",
        "nb_hidden  = 4\n",
        "nb_outputs = 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTj278ocJBr4"
      },
      "source": [
        "batch_size = 256"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXtJfTLDHzj0"
      },
      "source": [
        "### Spiking Neuron Model Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXUhPO68HxiO"
      },
      "source": [
        "tau_mem = 10e-3\n",
        "tau_syn = 5e-3\n",
        "\n",
        "alpha   = float(np.exp(-time_step/tau_syn))\n",
        "beta    = float(np.exp(-time_step/tau_mem))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4qVMUOBIy0E"
      },
      "source": [
        "Since we are technically stimulating an RNN, the neurons have to be simulated for a certain number of timesteps"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMYsYrC0IyAA"
      },
      "source": [
        "time_step = 1e-3\n",
        "nb_steps  = 200"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aeTfvQ2wJP1R"
      },
      "source": [
        "####Weight matrices \n",
        "\n",
        "Initializing weights from a normal distribution, the variance is scaled with the inverse square root of the number of input connections.\n",
        "\n",
        "Dale's Law is ignored here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxoWnuuOJMMm"
      },
      "source": [
        "weight_scale = 7*(1.0-beta) # this should give us some spikes to begin with\n",
        "\n",
        "w1 = torch.empty((nb_inputs, nb_hidden),  device=device, dtype=dtype, requires_grad=True)\n",
        "torch.nn.init.normal_(w1, mean=0.0, std=weight_scale/np.sqrt(nb_inputs))\n",
        "\n",
        "w2 = torch.empty((nb_hidden, nb_outputs), device=device, dtype=dtype, requires_grad=True)\n",
        "torch.nn.init.normal_(w2, mean=0.0, std=weight_scale/np.sqrt(nb_hidden))\n",
        "\n",
        "print(\"init done\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E48tqmmkJwqv"
      },
      "source": [
        "#@title The Spiking Non-linearity\n",
        "def spike_fn(x):\n",
        "  out = torch.zeros_like(x)\n",
        "  out[x > 0] = 1.0\n",
        "  return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDgY6EZFKhRZ"
      },
      "source": [
        "Initialize the synaptic currents and the membrane potentials at zero. Then implement a loop that stimulates the neuron models over time, and record the membrane potential and output spikes of all trials and all neurons."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6yvUproZKUEA"
      },
      "source": [
        "# tensors initialized with zeros for synaptic current and membrane potential\n",
        "syn = torch.zeros((batch_size, nb_hidden), device=device, dtype=dtype)\n",
        "mem = torch.zeros((batch_size, nb_hidden), device=device, dtype=dtype)\n",
        "\n",
        "# two lists to record the membrane potentials and output spikes\n",
        "mem_rec = []\n",
        "spk_rec = []\n",
        "\n",
        "# The simulation loop\n",
        "for t in range(nb_steps):\n",
        "  m_thr = mem - 1.0\n",
        "  out = spike_fn(m_thr)\n",
        "  rst = out.detach() # we do not want to backprop through the reset\n",
        "\n",
        "  new_syn = alpha*syn + h1[:, t]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwc9l63f2nOn"
      },
      "source": [
        "### LIF Neuron\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zslUSpx2bj4"
      },
      "source": [
        "class LIFneuron():\n",
        "  def.__init__(self, t_mem, t_syn):\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1FuClaX2w0e"
      },
      "source": [
        "### SuperSpike Network Implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Jd4w5fENh7J"
      },
      "source": [
        "class SuperSpike(nn.Module):\n",
        "  def.__init__(self):\n",
        "    super(SuperSpike, self).__init__()\n",
        "    self.layers = nn.Sequential()\n",
        "\n",
        "  def forward(self, x):\n",
        "    i\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}