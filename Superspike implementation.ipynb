{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Superspike implementation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ddG8pHV0kwc"
      },
      "source": [
        "Link to paper: [Zenke, Ganguli - 2018](https://direct.mit.edu/neco/article/30/6/1514-1541/8378)\n",
        "\n",
        "Zenke's [Tutorial](https://github.com/fzenke/spytorch) on Surrogate Gradient Descent using PyTorch.\n",
        "\n",
        "To Implement:\n",
        "1. LIF Neurons (maybe a class of such neurons)\n",
        "2. Fast Sigmoid Function\n",
        "\n",
        "Question:\n",
        "1. How to implement spiking neural network in pytorch? \n",
        "  * use RNNs as Zenke suggests in his tutorial?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPL18elCNSBW"
      },
      "source": [
        "#@title Dependencies\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "\n",
        "# import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A42hX2QOHrHl"
      },
      "source": [
        "dtype = torch.float\n",
        "device = torch.device(\"cpu\")\n",
        "\n",
        "# Uncomment the line below to run on GPU\n",
        "device = torch.device(\"cuda:0\") "
      ],
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Y-EjYFuIet1"
      },
      "source": [
        "### Network Architecture (Zenke)\n",
        "\n",
        "3 layer feed-forward neural network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GuJ0JQZbIoBS"
      },
      "source": [
        "nb_inputs  = 100\n",
        "nb_hidden  = 4\n",
        "nb_outputs = 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTj278ocJBr4"
      },
      "source": [
        "batch_size = 256"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXtJfTLDHzj0"
      },
      "source": [
        "### Spiking Neuron Model Setup (Zenke)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4qVMUOBIy0E"
      },
      "source": [
        "Since we are technically stimulating an RNN, the neurons have to be simulated for a certain number of timesteps"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMYsYrC0IyAA"
      },
      "source": [
        "time_step = 1e-3\n",
        "nb_steps  = 200"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXUhPO68HxiO"
      },
      "source": [
        "tau_mem = 10e-3\n",
        "tau_syn = 5e-3\n",
        "\n",
        "alpha   = float(np.exp(-time_step/tau_syn))\n",
        "beta    = float(np.exp(-time_step/tau_mem))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aeTfvQ2wJP1R"
      },
      "source": [
        "Initializing weights from a normal distribution, the variance is scaled with the inverse square root of the number of input connections.\n",
        "\n",
        "Dale's Law is ignored here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxoWnuuOJMMm"
      },
      "source": [
        "#@title Weight Matrcies\n",
        "weight_scale = 7*(1.0-beta) # this should give us some spikes to begin with\n",
        "\n",
        "w1 = torch.empty((nb_inputs, nb_hidden),  device=device, dtype=dtype, requires_grad=True)\n",
        "torch.nn.init.normal_(w1, mean=0.0, std=weight_scale/np.sqrt(nb_inputs))\n",
        "\n",
        "w2 = torch.empty((nb_hidden, nb_outputs), device=device, dtype=dtype, requires_grad=True)\n",
        "torch.nn.init.normal_(w2, mean=0.0, std=weight_scale/np.sqrt(nb_hidden))\n",
        "\n",
        "print(\"init done\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E48tqmmkJwqv"
      },
      "source": [
        "#@title The Spiking Non-linearity\n",
        "def spike_fn(x):\n",
        "  out = torch.zeros_like(x)\n",
        "  out[x > 0] = 1.0\n",
        "  return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTbcmdidrSL4"
      },
      "source": [
        "h1 = torch.einsum(\"abc,cd->abd\", (x_data, w1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDgY6EZFKhRZ"
      },
      "source": [
        "Initialize the synaptic currents and the membrane potentials at zero. Then implement a loop that stimulates the neuron models over time, and record the membrane potential and output spikes of all trials and all neurons."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6yvUproZKUEA"
      },
      "source": [
        "# tensors initialized with zeros for synaptic current and membrane potential\n",
        "syn = torch.zeros((batch_size, nb_hidden), device=device, dtype=dtype)\n",
        "mem = torch.zeros((batch_size, nb_hidden), device=device, dtype=dtype)\n",
        "\n",
        "# two lists to record the membrane potentials and output spikes\n",
        "mem_rec = []\n",
        "spk_rec = []\n",
        "\n",
        "# The simulation loop\n",
        "for t in range(nb_steps):\n",
        "  m_thr = mem - 1.0\n",
        "  out = spike_fn(m_thr)\n",
        "  rst = out.detach() # we do not want to backprop through the reset\n",
        "\n",
        "  new_syn = alpha*syn + h1[:, t]\n",
        "  new_mem = (beta*mem + syn)(1 - rst)\n",
        "\n",
        "  mem_rec.append(mem)\n",
        "  spk_rec.append(out)\n",
        "\n",
        "  mem = new_mem\n",
        "  syn = new_syn\n",
        "\n",
        "mem_rec = torch.stack(mem_rec, dim=1)\n",
        "spk_rec = torch.stack(spk_rec, dim=1)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpfHuhVHs138"
      },
      "source": [
        "def run_snn(inputs):\n",
        "\n",
        "  h1 = torch.einsum('abc,cd->abd', (inputs,w1))\n",
        "  syn = torch.zeros((batch_size, nb_hidden), device=device, dtype=dtype)\n",
        "  mem = torch.zeros((batch_size, nb_hidden), device=device, dtype=dtype)\n",
        "  # lists to record the membrane potentials and the synaptic currents:\n",
        "  mem_rec = []\n",
        "  spk_rec = []\n",
        "  # loop to simulate time\n",
        "  for t in range(nb_steps):\n",
        "    mthr = mem - 1.0\n",
        "    out = spike_fn(mthr)\n",
        "    rst = out.detach()  # do not want to backpropagate through reset\n",
        "\n",
        "    new_syn = alpha*syn + h1[:, t]\n",
        "    new_mem = (beta*mem + syn)(1 - rst)\n",
        "\n",
        "    mem_rec.append(mem)\n",
        "    spk_rec.append(out)\n",
        "\n",
        "    mem = new_mem\n",
        "    syn = new_syn\n",
        "  \n",
        "  # create tensors to stack the elements in the recording lists\n",
        "  mem_rec = torch.stack(mem_rec, dim=1)\n",
        "  spk_rec = torch.stack(spk_rec, dim=1)\n",
        "\n",
        "  # readout layer\n",
        "  h2 = torch.einsum('abc,cd->abd', (spk_rec, w2))\n",
        "  flt = torch.zeros((batch_size, nb_outputs), device=device, dtype=dtype)\n",
        "  out = torch.zeros((batch_size, nb_outputs), device=device, dtype=dtype)\n",
        "  out_rec = [out]\n",
        "  for t in range(nb_steps):\n",
        "    new_flt = alpha*flt + h2[:, t]\n",
        "    new_out = beta*out + flt\n",
        "\n",
        "    flt = new_flt\n",
        "    out = new_out\n",
        "\n",
        "    out_rec.append(out)\n",
        "\n",
        "  out_rec = torch.stack(out_rec, dim=1)\n",
        "  other_recs = [mem_rec, spk_rec]\n",
        "  return out_rec, other_recs\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1FuClaX2w0e"
      },
      "source": [
        "## SuperSpike Implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Jd4w5fENh7J"
      },
      "source": [
        "class SuperSpike(nn.Module):\n",
        "  def.__init__(self):\n",
        "    super(SuperSpike, self).__init__()\n",
        "    self.layers = nn.Sequential()\n",
        "\n",
        "  def forward(self, x):\n",
        "    i\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYlUxv4s413Q"
      },
      "source": [
        "#@title Surrogate Gradient\n",
        "\n",
        "class SurrGradSpike(torch.autograd.Function):\n",
        "\n",
        "  scale = 100.0 # controls the steepness of the gradient\n",
        "\n",
        "  @staticmethod\n",
        "  def forward(ctx, input):\n",
        "    '''\n",
        "    computes a step-function on the input. ctx is a context variable\n",
        "    that stores information needed later for backpropagation\n",
        "    '''\n",
        "    ctx.save_for_backward(input)\n",
        "    out = torch.zeros_like(input)\n",
        "    out[input > 0] = 1\n",
        "    return out\n",
        "\n",
        "  @staticmethod\n",
        "  def backward(ctx, grad_output):\n",
        "    '''\n",
        "    In the backward method, we recieve a tensor we need to compute \n",
        "    the surrogradient of the loss with respect to the input. \n",
        "    Here we use the negative half of the fast sigmoid as in \n",
        "    Zenke & Ganguli 2018.\n",
        "    \n",
        "    '''\n",
        "    input, _ = ctx.saved_tensors\n",
        "    grad_input = grad_output.clone()\n",
        "    grad = grad_input/(SurrGradSpike.scale*torch.abs(input)+1.0)**2\n",
        "    return grad\n",
        "\n",
        "# overwrite the spike function with the surrograte gradient function\n",
        "# using the apply method\n",
        "spike_fn = SurrGradSpike.apply\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rV65siTAc8sd"
      },
      "source": [
        "#### Loss Function\n",
        "\n",
        "The van rossum distance is evaluated as:\n",
        "$$ L = (\\alpha*S_i - \\alpha*\\hat{S_i})^2 $$\n",
        "\n",
        "where $ \\alpha $ is a double exponential filter. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JVWDywkDScAN"
      },
      "source": [
        "### Double Exponential Filter\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Cld4VdEcwY2"
      },
      "source": [
        "\n",
        "def doubleExponential(spike_train, dt, t_rise, t_decay, time):\n",
        "  \"\"\"\n",
        "  Implements the double exponential kernel\n",
        "  input:\n",
        "    spike_train - time series of spikes containing ones and zeros\n",
        "    dt\n",
        "    t_rise - time constant of first exponential filter\n",
        "    t_decay - time constant of second exponential filter\n",
        "    time - tuple with start & stop time (wrt spike_train) for the convolution\n",
        "  Returns:\n",
        "    the convolved double exponential product\n",
        "  \"\"\"\n",
        "  time_range = time[1] - time[0]\n",
        "\n",
        "  z = torch.zeros(time_range)\n",
        "  z_hat = torch.zeros(time_range)\n",
        "\n",
        "  for t in range(time_range):\n",
        "    z[t+1] =  z[t] + (-z[t]/t_rise + spike_train[t])*dt\n",
        "    z_hat[t+1] = z_hat[t] + (-z_hat[t] + z[t])*dt/t_decay\n",
        "\n",
        "  return z_hat"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HP2GM8I4fUJv"
      },
      "source": [
        "### Hebbian Coincidence Detection & Synaptic Eligibility Trace\n",
        "\n",
        "$$ \\frac{dw_{ij}}{dt} = r\\int_{-\\infty}^t ds\\ e_i(s)\\ \\alpha * [\\sigma'(U_i(s))(\\epsilon*S_j(s))]  $$\n",
        "\n",
        "The evalutation of this equation requires:\n",
        "1. evaluation of presynaptic traces\n",
        "2. evaluation of hebbian coincidence and computation of the synaptic eligibility traces\n",
        "3. compuatation and propagation of error signals\n",
        "4. integration of this equation and weight update\n",
        "\n",
        "\n",
        "\n",
        "Here $ \\lambda_{ij} = \\sigma'(U_i(s))(\\epsilon*S_j(s)) $ is the eligibility trace.\n",
        "\n",
        "Fast sigmoid: $$   \\sigma(x) = \\frac{x}{1 + |x|} $$\n",
        "\n",
        "So, $ \\sigma'(U_i) = \\frac{1}{(1 + |h_i|)^2} $\n",
        "\n",
        "where $ h_i = \\beta(U_i - \\nu) $\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_D7gVtIzIlX"
      },
      "source": [
        "def presynaptic_trace(value_exp1, value_exp2, spike, args):\n",
        "  \"\"\"\n",
        "  Input:\n",
        "    value_exp1 - 1-D array containing values of the single\n",
        "                 exponential trace at the previous timestep shape: (n, 1)\n",
        "    value_exp2 - 1-D array containing values of the second \n",
        "                 exponential trace at the previous timestep, shape: (n,1)\n",
        "    spike - 1-D array containing 0s or 1s for n presynaptic neurons\n",
        "    args['t_rise'] - \n",
        "    args['t_decay'] -\n",
        "  Returns:\n",
        "    the value of the presynaptic trace at the current timestep\n",
        "  \"\"\"\n",
        "  dt = args['timestep_size']\n",
        "  t_rise = args['t_rise']\n",
        "  t_decay = args['t_decay']\n",
        "\n",
        "  #print(\"Presynaptic Traces value_exp1, shape\", value_exp1.shape)\n",
        "  #print(\"Presynaptic Traces value_exp2, shape\", value_exp2.shape)\n",
        "  \n",
        "  z = value_exp1 + (-value_exp1/t_rise + spike)*dt\n",
        "  z_hat = value_exp2 + (-value_exp2 + value_exp1)*dt/t_decay\n",
        "  \n",
        "  return z, z_hat"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SeRfLDcodla6"
      },
      "source": [
        "def eligibility_trace(mem, spike_train, args):\n",
        "  \"\"\"\n",
        "  input:\n",
        "    mem: membrane potential of i-th neuron for all \n",
        "         relevant timesteps, 1-D array shape: (timesteps)\n",
        "    spike_train: j-th neuron, 1-D array, shape: (timesteps)\n",
        "    thres: firing threshold\n",
        "  Returns:\n",
        "    eligibility trace\n",
        "  \"\"\"\n",
        "  thres = args['thres']\n",
        "  t_rise = args['t_rise']\n",
        "  t_decay = args['t_decay']\n",
        "  \n",
        "  beta = 1 # mV^-1\n",
        "  h_i = beta*(mem - thres)\n",
        "\n",
        "  post = 1 / (1 + torch.abs(h_i))**2 \n",
        "  pre_synaptic_trace = doubleExponential(spike_train, dt, t_rise, t_decay, time)\n",
        "\n",
        "  hebbian = post * pre_synaptic_trace #hebbian coincidence term\n",
        "\n",
        "  #synaptic eligibility trace\n",
        "  eligibility_trace = doubleExponential(hebbian, dt, t_rise, t_decay, time)\n",
        "\n",
        "  return elibility_trace"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BATIjT7BlD1t"
      },
      "source": [
        "### Error Signal"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4fIjji7XOok"
      },
      "source": [
        "#@title Output Error Signal\n",
        "\n",
        "def error_signal(spike_train, desired_spike_train):\n",
        "  \"\"\"\n",
        "  Returns the error signal (time series)\n",
        "  \"\"\"\n",
        "  # output spike train\n",
        "  filter_1 = doubleExponential(spike_train, dt, t_rise,\n",
        "                               t_decay, time)\n",
        "  # desired spike train\n",
        "  filter_2 = doubleExponential(desired_spike_train, dt, t_rise,\n",
        "                               t_decay, time)\n",
        "  \n",
        "  error = filter_2 - filter_1\n",
        "  return error\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0epZHtN-DCY"
      },
      "source": [
        "def error_signal2(value_exp1, value_exp2, output, target, args):\n",
        "  \"\"\"\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  t_rise = args['t_rise_alpha']\n",
        "  t_decay = args['t_decay_alpha']\n",
        "  dt = args['timestep_size']\n",
        "\n",
        "  difference = target - output\n",
        "\n",
        "  z = value_exp1 + (-value_exp1/t_rise + difference)*dt\n",
        "  z_hat = value_exp2 + (-value_exp2 + value_exp1)*dt/t_decay\n",
        "\n",
        "\n",
        "  return z, z_hat\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yq0UfjVzQZti"
      },
      "source": [
        "#@title Feedback Signal\n",
        "\n",
        "def feedback_signal():\n",
        "  \"\"\"\n",
        "  \n",
        "  Returns:\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "\n",
        "  return feedback"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRJ_QKUSTO0F"
      },
      "source": [
        "### Per Parameter Learning Rate\n",
        "\n",
        "Zenke & Ganguli (2018) used a per parameter learning rate. **bold text**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMDZpUAxTNOb"
      },
      "source": [
        "def learning_rate():\n",
        "  \"\"\"\n",
        "\n",
        "  \"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwsyQm0lXdch"
      },
      "source": [
        "### Regularization Term\n",
        "\n",
        "Heterosynaptic regularization term to the learning rule of the hidden layers to avoid pathologically high firing rates.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPXCD25nXg8k"
      },
      "source": [
        "def regularization_term():\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJKFm5liSxym"
      },
      "source": [
        "### Poisson Spike Trains\n",
        "\n",
        "Based on the method suggested by David Heeger [here](https://www.cns.nyu.edu/~david/handouts/poisson.pdf)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6HSjSVcSDKA"
      },
      "source": [
        "def Poisson_trains(n, lam, timesteps, dt):\n",
        "  \"\"\"\n",
        "\n",
        "  inputs:\n",
        "    n - number of poisson spike trains \n",
        "    lam - 1-D array containing mean value of poisson trains\n",
        "  Returns\n",
        "\n",
        "  \"\"\"\n",
        "  trains = torch.zeros((n, timesteps), device=device, dtype=dtype)\n",
        "  unif = torch.rand((n, timesteps), device=device, dtype=dtype)\n",
        "\n",
        "#  counter = 0\n",
        "  for i in range(n):\n",
        "    trains[unif <= lam[i]*dt] = 1\n",
        "#    counter += len(unif <= lam[i]*dt)\n",
        "#  print(\"Total No. of Spikes\", counter)\n",
        "\n",
        "  return trains"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRVvazAW4264"
      },
      "source": [
        "trains = Poisson_trains(1, 1000*np.ones(10), 1000, 1e-4)\n",
        "\n",
        "#print(trains)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BoctDxVETK6F"
      },
      "source": [
        "#@title Step Function for Spikes\n",
        "def spike_fn(x, thres):\n",
        "  \"\"\"\n",
        "  Implements a heaviside function centred at the firing threshold\n",
        "  \"\"\"\n",
        "  x = x - thres\n",
        "  out = torch.zeros_like(x)\n",
        "  out[x > 0] = 1\n",
        "  return out"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hoVT0g8hHomP"
      },
      "source": [
        "def van_rossum_loss(output, target, args):\n",
        "\n",
        "  z = 0\n",
        "  z_hat = 0\n",
        "  t_rise = args['t_rise_alpha']\n",
        "  t_decay = args['t_decay_alpha']\n",
        "  dt = args['timestep_size']\n",
        "\n",
        "  loss = 0\n",
        "\n",
        "  #output = output.flatten(start_dim=1)\n",
        "\n",
        "  #print(\"Output Spike Train Shape:\", output.shape)\n",
        "  #print(\"Target Spike Train Shape:\", target.shape)\n",
        "\n",
        "  for i in range(len(output)):\n",
        "\n",
        "    difference = target[i] - output[i]\n",
        "  #  print(difference.shape)\n",
        "    z = z + (-z/t_rise + difference)*dt\n",
        "    z_hat = z_hat + (-z_hat + z)*dt/t_decay\n",
        "    \n",
        "    loss += dt*z_hat**2 \n",
        "\n",
        "  return (1/2)*loss\n",
        "\n"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ct7gcmMaHQif"
      },
      "source": [
        "def eligibility_trace2(value_exp1, value_exp2, hebbian, args):\n",
        "  \"\"\"\n",
        "  i: no. of presynaptic neurons\n",
        "  j: no. of postsynaptic neurons\n",
        "  Input:\n",
        "    value_exp1 - 2-D array containing values of the single exponential\n",
        "                 trace at the previous timestep. Shape: (i, j)\n",
        "    value_exp2 - 2-D array containing values of the second exponential\n",
        "                 trace at the previous timestep Shape: (i, j)\n",
        "    hebbian - 2-D array\n",
        "    args['t_rise_alpha']\n",
        "    args['t_decay_alpha']\n",
        "  Returns:\n",
        "\n",
        "  \"\"\"\n",
        "  dt = args['timestep_size']\n",
        "  t_rise = args['t_rise_alpha']\n",
        "  t_decay = args['t_decay_alpha']\n",
        "\n",
        "#  print(\"last eligibility Value_exp1 shape:\", value_exp1.shape)\n",
        "#  print(\"last eligibility Value_exp2 shape:\", value_exp2.shape)\n",
        "#  print(\"hebbian shape\", hebbian.shape)\n",
        "\n",
        "  z = value_exp1 + (-value_exp1/t_rise + hebbian)*dt\n",
        "  z_hat = value_exp2 + (-value_exp2 + value_exp1)*dt/t_decay\n",
        "\n",
        "  return z, z_hat"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wDUPS2aHRRG7"
      },
      "source": [
        "### Single Neuron Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50_ZIOtqD9ov"
      },
      "source": [
        "Property | Value|\n",
        "-----| -----|\n",
        "threshold | -50 mV\n",
        "U_rest | -60 mV\n",
        "tau_mem| 10 ms\n",
        "tau_syn| 5 ms\n",
        "tau_ref| 5 ms\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NatNAnH8RP0m"
      },
      "source": [
        "nb_inputs = 100 # 100 spike trains as inputs that repeat every 500 ms\n",
        "nb_outputs = 1 \n",
        "\n",
        "batch_size = 256\n",
        "\n",
        "nb_steps = 5000\n",
        "timestep_size = 1e-4 # 0.1 msec timesteps\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0XrBRxpDxME"
      },
      "source": [
        "# LIF Neuron Model Parameters\n",
        "args = {'thres': 1,\n",
        "        'U_rest': -60,\n",
        "        'tau_mem': 1e-2,\n",
        "        'tau_syn': 5e-3,\n",
        "        'tau_ref': 5e-3,\n",
        "        't_rise': 5e-3, # the pre-synaptic double exponential kernel rise time\n",
        "        't_decay': 1e-2, # the pre-synaptic double exponential kernel decay time\n",
        "        'timestep_size': 1e-4,\n",
        "        't_rise_alpha': 5e-3,\n",
        "        't_decay_alpha': 1e-2} "
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZtO16h80uzyo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "outputId": "bdcfb164-2374-4613-b91c-e8042c2149f2"
      },
      "source": [
        "tau_syn = args['tau_syn']\n",
        "tau_mem = args['tau_mem']\n",
        "\n",
        "alpha = float(torch.exp(-timestep_size/tau_syn))\n",
        "beta = float(torch.exp(-timestep_size/tau_mem))\n",
        "print(type(beta))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-ba35893dc3f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtau_mem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tau_mem'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mtimestep_size\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtau_syn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mbeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mtimestep_size\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtau_mem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "id": "6e_2mHe4Ip6j",
        "outputId": "eea9abdd-a506-43e1-8238-112b13415695"
      },
      "source": [
        "def weight_update(input, output, target, mem, args):\n",
        "  update = torch.zeros(nb_outputs)\n",
        "\n",
        "  for i in range(nb_outputs):\n",
        "    update[i] = error_signal(output, target)*eligibility_trace(mem, input[i]\n",
        "  update = error_signal(output, target)*\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-17-76c5f9cbcee3>\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    update = error_signal(output, target)*\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBlHb3qGdeE9"
      },
      "source": [
        "#@title Input Spike Trains\n",
        "\n",
        "spk_freq = 10 # not sure about this, but assuming it since the paper\n",
        "# uses 10 Hz frequency as the target output frequency (actually \n",
        "# 5 equidistant spikes over 500 ms)\n",
        "\n",
        "input_trains = Poisson_trains(100, spk_freq*np.ones(100),\n",
        "                              nb_steps, timestep_size)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmSXUKaCRXZT"
      },
      "source": [
        "#@title Target Spike Train\n",
        "## 5 equidistant spikes spread over 0.5 secs\n",
        "target = torch.zeros(nb_steps)\n",
        "target[:: nb_steps//5] = 1"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJP4zBk6T5F9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d698848-f5c2-429b-814c-3709844fc2ed"
      },
      "source": [
        "#@title Weight Initialization\n",
        "\n",
        "weight_scale = 7*(1 - beta) # copied from spytorch\n",
        "\n",
        "weights = torch.empty((nb_inputs), device=device, dtype=dtype)\n",
        "torch.nn.init.normal_(weights, mean=0.0, std=weight_scale/np.sqrt(nb_inputs))\n",
        "print(\"Weight initialization done\")"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weight initialization done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLTjfwXjaZ0U",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "outputId": "1aa81bf5-6eda-4eb1-a42b-1e4770bf0199"
      },
      "source": [
        "mem = torch.zeros(nb_outputs, device=device, dtype=dtype)\n",
        "syn = torch.zeros(nb_outputs, device=device, dtype=dtype)\n",
        "\n",
        "epochs = 10\n",
        "thres = args['thres']\n",
        "\n",
        "loss_rec = []\n",
        "for i in tqdm(range(epochs)):\n",
        "\n",
        "  m = 0\n",
        "  mem_rec = []\n",
        "  spk_rec = []\n",
        "\n",
        "  eligibility_trace_record = torch.zeros((nb_inputs, nb_steps), device=device, dtype=dtype)\n",
        " # pre_trace_rec = torch.zeros((nb_inputs, nb_inputs, nb_steps), device=device, dtype=dtype)\n",
        "  \n",
        "\n",
        "  eligibility_rec = []\n",
        "  pre_trace_rec = []\n",
        "\n",
        "  out_spks = torch.zeros(nb_steps, device=device, dtype=dtype)\n",
        "  \n",
        "  last_presynaptic_traces = [torch.zeros(nb_inputs, device=device, dtype=dtype),\n",
        "                             torch.zeros(nb_inputs, device=device, dtype=dtype)],\n",
        "  last_eligibility_traces = [torch.zeros(nb_inputs, device=device, dtype=dtype),\n",
        "                             torch.zeros(nb_inputs, device=device, dtype=dtype)] # not sure about the shape here, might have to recheck\n",
        "\n",
        "  last_error_values = [torch.zeros(nb_inputs, device=device, dtype=dtype),\n",
        "                            torch.zeros(nb_inputs, device=device, dtype=dtype)]\n",
        "  for t in range(nb_steps):\n",
        "\n",
        "    weighted_inp = input_trains[:, t] * weights\n",
        "\n",
        "    out = spike_fn(mem, thres)\n",
        "    reset = out\n",
        "\n",
        "    spk_rec.append(out)\n",
        "    mem_rec.append(mem)\n",
        "\n",
        "    new_syn = alpha*syn + weighted_inp\n",
        "    new_mem = (beta*mem + syn*(1 - beta))*(1 - reset)\n",
        "\n",
        "    mem = new_mem\n",
        "    # compute presynaptic traces\n",
        "    presynaptic_traces = presynaptic_trace(last_presynaptic_traces[0],\n",
        "                                           last_presynaptic_traces[1],\n",
        "                                           input_trains[:, t], args)\n",
        "    \n",
        "    last_presynaptic_traces = presynaptic_traces\n",
        "    ##pre_trace_rec.append(presynaptic_traces)\n",
        "\n",
        "    # evaluate hebbian coincidence and synaptic eligibility traces\n",
        "    h = mem - thres\n",
        "    post = 1 / (1 + torch.abs(h))**2\n",
        "\n",
        "  \n",
        "\n",
        "    hebbian = post * presynaptic_traces[1]\n",
        "\n",
        "    synaptic_eligibility = eligibility_trace2(last_eligibility_traces[0],\n",
        "                                     last_eligibility_traces[1],\n",
        "                                     hebbian, args)\n",
        "\n",
        "    last_eligibility_traces = synaptic_eligibility\n",
        "\n",
        "  \n",
        "    error = error_signal2(last_error_values[0], last_error_values[1],\n",
        "                          out, target[t], args)\n",
        "    \n",
        "    last_error_values = error\n",
        "    # for minibatching weight updates in time\n",
        "  #  print(\"Error shape:\", error[1].shape)\n",
        "  #  print(\"Eligibility Shape:\", synaptic_eligibility[1].shape)\n",
        "\n",
        "    m += error[1] * synaptic_eligibility[1]\n",
        "  \n",
        "  #  print(\"\\n\")\n",
        "  print(m.shape)\n",
        "  weights += m\n",
        "  spk_rec = torch.stack(spk_rec, dim=0)\n",
        "  loss = van_rossum_loss(spk_rec, target, args)\n",
        "  print(\"Loss =\", loss)\n",
        "  loss_rec.append(loss)\n",
        "\n",
        "\n",
        "  spk_rec = torch.flatten(spk_rec)\n",
        "  print(spk_rec)\n",
        "\n",
        "  plot_single_train(spk_rec, nb_steps, timestep_size)\n",
        "  plt.show()\n",
        "\n",
        "print(loss_rec)\n",
        "\n",
        "\n",
        "plt.plot(loss_rec)\n",
        "    \n",
        "\n",
        "    \n",
        "  \n",
        "\n",
        "    \n",
        "\n",
        "    \n"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/10 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-125-de5db8f13fce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mmem_rec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mnew_syn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msyn\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mweighted_inp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0mnew_mem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmem\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msyn\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODhULLJKzuli"
      },
      "source": [
        "#### Raster Plot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RrKL8CLRqZfb"
      },
      "source": [
        "def plot_single_train(spike_train, nb_steps, timestep_size, idx=0):\n",
        "\n",
        "  positions = np.arange(0, nb_steps*timestep_size, timestep_size)\n",
        "  spike_positions = positions[spike_train == 1]\n",
        " # print(spike_positions)\n",
        "  plt.eventplot(spike_positions, lineoffsets=idx)\n",
        "  #plt.show()\n",
        "\n",
        "def plot_trains(spike_trains, title='Spike Trains'):\n",
        "  plt.figure(dpi = 100)\n",
        "  for i in range(len(spike_trains)):\n",
        "    plot_single_train(spike_trains[i], nb_steps, timestep_size, idx=i)\n",
        "  plt.title(title)\n",
        "  plt.xlabel('Time (in sec)')\n",
        "  plt.ylabel('Spike Train No.')\n",
        "  plt.show()"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 652
        },
        "id": "jCIK1uZytXic",
        "outputId": "6bc3e0ac-b693-4642-b8e3-b002e4e793fe"
      },
      "source": [
        "plot_single_train(target, nb_steps, timestep_size)\n",
        "plt.show()\n",
        "\n",
        "plot_trains(input_trains, title = \"Input Trains\")"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhwAAAGDCAYAAABgJsl3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de5gkdXXw8e9hlcWF3UVfBIKIKCqCgIioQVGMqxHv90CMCkZ4BRVEvCwoEVESUbm9EUElCmqIVxTvQSCCFxCzIiCKitwEkQUUWO4InPePqoHeZma2u6eru6r6+3mefma6urr61K+qZ06fU1UdmYkkSVKVVht3AJIkqf1MOCRJUuVMOCRJUuVMOCRJUuVMOCRJUuVMOCRJUuVMOCRJUuVMOCRJUuVMOCRJUuVMOCSpFBHvjwgvvyxVwIRDmhARsWtEZERsO+5YACJiQfkP/lk9zHtZGfuqbrtWH7mkQTxg3AFImlgLgAPL309fxbz7AGt13H8B8I/A24HrOqafOceYDgYOmeMyJE3DhENS7WXmSZ33I2J9ioTjpMy8bKbnRcSamXlLH69zF3DXoHFKmpktFWmCRcTxEXFzRDwsIk4qf782Ig6NiHkd821ctizeGRFvj4jLI+K2iDgjIrboWubpEXH6DK912dTygGvLhw7saIm8fwjrsklEfDcibgJOKB97RkR8JSL+EBF3RMQVEXFERDyoaxn3O4ajjOuoiHhZRFxQPv9XEbFj13wLI+LIsv1zR0RcExGnRMQ2g66T1CZWOCTNA04GzgbeCTwHeAdwMXBM17yvBxYCHwfWAN4G/E9EbJmZy/t4zWuBPcvlfx34Wjn9/AHXYcoDKNblxxTrcms5/dUULZxjgD8DTwH2AjYsH1uV7YFXAEcDNwF7AydGxEaZ+edynk8ArwKOAn4N/J/yeZsB58xxvaTGM+GQtAbwpcz8YHn/ExFxDvBG7p9wPBp4TGb+ESAi/psiUVkK7NvrC2bmLRHx1XL552fmf85xHabMB76Smft3TV+ambd13P9URPwe+LcyafjDKpa7GbB5Zl4MEBE/AM6jaOscVc7zQuDYzHxHx/M+MuiKSG1jS0USFJ/OO/0IeNQ08500lWwAZObPKBKOF1QYW7+6kyQ6k42IWDMi1qE4wDSAJ/awzFOnko1yeecDK1h5jG4AnhoRGwwauNRmJhySbs/Ma7umXQ88eJp5L5pm2u+AjYcd1IDuAq7snhgRG5XHePwFuJmipXNG+fDiHpY7XQWke4zeDWwBXBERPyuPB5kuaZMmkgmHpLuHvLyZLpw1b4bpw3RHZt7TOaE8+PUUipbHh4GXAc8Fdi1n6eXv4ExjFFO/ZOaXKSoeewFXAe8CfhURz+8jfqm1PIZDUj8eM820xwKXddy/nunbMY/ouj+qK3puSRHjLpn5uamJEfHcYb9QZv6J4sDSoyNiXYqDRd8LfG/YryU1jRUOSf14WUQ8bOpORDwFeCor/0O9GHhcRDy0Y74nAE/vWtbUGSRrVxTrlKnqxL3ViIgIijNshiIi5kXESq2ZzLyGotIxf1ivIzWZFQ5J/fg98OOIOIbiH+k+FKeZdp6N8RmKM1ZOjohPA+sCewC/AhZNzZSZt0XEr4GdIuJ3wF+ACzLzgiHH/BuKJOjQMllaAbyS6Y9RGdRC4MryzJvzKI4TeQ7wZIpTjKWJZ4VDUj8+B3wMeCtFq+BXwLPLVgIAmXkhxfU6FgOHAy8BXsf016LYDfgjcATwBYrrWAxVZv4VeDFwLrA/xeXULypjHJZbKVopWwMHUazPpsCbM/PwIb6O1FiR6RcjSppdeWXQS4F3Zeah441GUhNZ4ZAkSZUz4ZAkSZUz4ZAkSZXzGA5JklQ5KxySJKlyJhySJKlyXviLe686uAFw07hjkSSpgRYCV+Usx2mYcBQ2YJpvmJQkST3bkOJCftMy4SjcBHDFFVewaNGiVc0rSZJKK1as4OEPfzisoktgwtFh0aJFJhySJFXAg0YlSVLlTDgkSVLlTDgkSVLlTDgkSVLlTDgkSVLlTDgkSVLlTDgkSVLlxppwRMQzI+JbEXFVRGREvKzr8YiID0TEnyLitog4NSIe0zXPQyLihIhYERE3RMSnI2Kt0a6JJEmazbgrHGsC5wFvmeHxdwN7A3sATwVuAU6OiDU65jkBeDzwXOBFwDOBT1UVsCRJ6l/M8j0rIxURCbw8M08q7wdwFXBYZh5aTlsMLAd2zcwvRsRmwK+BJ2fmsnKeHYHvAhtm5lUzvNZ8YH7HpIXAlTfeeKNXGpUkqQ8rVqxg8eLFAIszc8VM8427wjGbRwLrA6dOTcjMG4Gzge3KSdsBN0wlG6VTgXsoKiIz2R+4sePmF7dJklShOicc65c/l3dNX97x2PrANZ0PZuZdwF865pnOh4DFHbcN5xqsJEma2UR+eVtm3gHcMXW/6N5IqqNb77yLzd93MgC//sDzWLD6+P5s1SkWqWnqXOG4uvy5Xtf09ToeuxpYt/PBiHgA8JCOeSRJ0pjVOeG4lCJpWDI1ISIWURybcVY56Sxg7Yh4Usfznk2xXmePKE5JkrQKYz1LpbxexqPLu78A9gV+APwlM/8QEUuB/YBdKBKQDwJbAZtn5u3lMr5HUfXYA3ggcBywLDNf00cci4AbqzpLZZRl2LqUfOsSh9Q0vncmT9O3ea9nqYx7rbalSDCmHF7+/CywK/ARimt1fApYG/gxsONUslH6J+Ao4DSKs1NOpLh2hyRJqonaXIdjnKqucGgy1PlTSp1j033cTtVa1fh2Pr7sgCVse/BpM847jNcb17KGrQ3X4ZAkSS1hwiFJkipnSwVbKppMs5VoOx+b7nEV6lzmVr21ad+xpSJJkmrDhEOSJFXOlgq2VNQcbSrDariq2Dfc39QLWyqSJKk2rHDQrAqHnziq4bg2k9tNGj8rHJIkqTZMOCRJUuVsqdCslorqydJ+dUY9tm5LqT+2VCRJUm2YcEiSpMrZUsGWyqgNu2Q9SSXwua5r08aqbvHWLR41Txv3IVsqkiSpNkw4JElS5Wyp0L6WShtLdk3nNtGkq/I90Lb3V9PWx5aKJEmqDSscjLfC0bRMVu3gftc+VW/TfpY/l1iasm82Jc5OVcVshUOSJNWGCYckSaqcLRXad9CotCpNLAdrbtzmqootFUmSVBsmHJIkqXK2VLCl0i9Ls9VyfLUq7iOqE1sqkiSpNqxw0NwKR9s+5Yxyfdo2dqqfUe1j7svq1rlPLDtgCdsefBpQ3f5hhUOSJNWGCYckSaqcLRWa21JpomGUf9tUQq7rutQ1Ls1d57adUrdtPCn731zXsy7jZEtFkiTVhgmHJEmqnC0V2v1tsXUpuVWpu0Rc5/WchO2hmY3qG1eriknVafJ2sKUiSZJqw4RDkiRVzpYKo2mpNLlcJjVNG95vbViHJmrLmSOjZEtFkiTVhhUO2n3QaJtN6thN6nqvSh3HpY4xScNmhUOSJNWGCYckSaqcLRW8tLl6Y3m8OabbVpOy/dq+nt3rB7R6fXsx7m1uS0WSJNWGCYckSapcrVsqETEPeD/wWmB94CrgeODgLAOPiAAOAnYH1gZ+AuyZmRf18Tqta6mMu8SmZnA/mbuqvn3VbTN8vY6pY9+ftrRUlgJ7Am8FNivvvxvYq2OedwN7A3sATwVuAU6OiDVGG6okSZpJ3Ssc3waWZ+YbO6adCNyWma8tqxtXAYdl5qHl44uB5cCumfnFHl+ndRWO2Vx38+1se/BpACw7YAnrrDXa3GzYnx78NNJMM223uWxPvwxRGr22VDjOBJZExGMBIuIJwPbA98rHH0nRajl16gmZeSNwNrDdTAuNiPkRsWjqBiysKH5JkgTUPT0/BFgE/CYi7gbmAe/NzBPKx9cvfy7vet7yjsemsz9w4DADlSRJM6t7S2Vn4KPAu4BfAVsDRwL7ZuZnI+JpFAeJbpCZf+p43peBzMydZljufGB+x6SFwJVtaamMouzb1NJyU+OWNH6jOOi0iX+jem2p1H1NPgoc0nEsxi8j4hEUFYrPAleX09cD/tTxvPWAc2daaGbeAdwxdb84FESSJFWl7sdwLADu6Zp2N/fFfSlF0rFk6sHymIynAmeNIkBJkrRqdW+pHA88B3gTRUvlicCngM9k5tJynqXAfsAuFAnIB4GtgM0z8/YeX6e1Z6k0sTzXJk0c/7rFXLd41E5eo2NwbWmp7EWRQBwNrEtxCuwngQ90zPMRYE2KRGRt4MfAjr0mG5IkqXq1Tjgy8yZgn/I20zwJvK+8SZKkGqp1S2VURtFSmeQy3CSv+6o4NqPnmEvD1ZYLf0mSpBawwkG7DxpVfdX5k3adYxumSVnP2TgG49f0bWCFQ5Ik1YYJhyRJqpwtFWypNE3Ty48aLfcXqVq2VCRJUm2YcEiSpMrZUqG+LZUqSsHTLdOS88zaOjaDrFdbx6Ku+h3vSbk0d53jr3NsVbKlIkmSasMKB/WtcEi9mumTVR0+cdUhBjVD574ype37TBveH1Y4JElSbZhwSJKkytlSwZbKdEZd5mtDWbEOHEepvtr6/rSlIkmSasOEQ5IkVc6WCrZU2sRW0MyaFGuT1Glc6xRL07VhLEe1DrZUJElSbZhwSJKkytlSwZZK09W19FllXL0su67j0otJvADUqgy6PZu8H6gZbKlIkqTasMJBfSscfjLRTJq6b4wy7qaOkdQ0VjgkSVJtmHBIkqTK2VKhvi2VSdWUUnhT4pSaYrqDhZcdsIR11lpjTBFVqy1/Q2ypSJKk2jDhkCRJlRtaSyUiXkpRTvncUBY4Qm1vqfRTtmtLiW+cmjaGTYtXUr2Mo6XyYeC4IS5PkiS1xNA+ymTm44a1LEmS1C6epUL7WyoaP9sW6pX7Sm+qGifHv3+VtlQiYoeI+FZE/L68fTMinjFosJIkqd36rnBExGspjtX4GvCTcvLTgZcDu2bmfw01whGwwnF/Zvnt4bYcvu4xBRozxu4PGrZeKxyD7GnvBd6dmUd0TPv3iNgX+BegcQmHJEmq1iAtlUcB35pm+jeBR84tHEmS1EaDtFR+D3w0Mz/ZNX0P4B2Z+ZghxjcStlRmZwlW49aEfXDUMTZhTHo1jnWZy2tOdwn2pm+DuaiypXIYRQtla+DMctrTgV2Btw2wPEmS1HJ9JxyZeUxEXA28A/iHcvKFwE6Z+Y1hBidJktrB63AwmpZKm8qfqp9R7F/uw6qS+1dz+W2xkiSpNnqucETEpcCqZs7M3GTOUY2YB42ORtM/wRi/JN1fFQeNHjnLYxsDbwLm97E8SZI0IXpOODLz/3VPi4iHUFzsa0/gbGDp8EKTJEltMdBBoxHxIGBf4J3A5cB7MvO7Q45t6rUeBnwYeD6wAPg98IbMXFY+HsBBwO7A2hSXW98zMy/q4zVsqQygnxK95fz7q/OY1Dm2UXIc+lOH8aoyhjqsXx1VctBoRMwrL/B1CbAbsDfwxAqTjQdTJBB/pUg4Nqc4Hff6jtneXcaxB/BU4Bbg5IhYo4qYJElS/3pOzyLiH4CDKaoI/wock5l3VhVYaSlwRWa+oWPapR0xBbAPcPDUNUAi4vXAcuBlwBcrjk+SJPWgn7NU7gFuA74AzFgyycx9hxMaRMSvgZOBDYEdgD8CR2fmseXjjwIupqiynNvxvDOAczNz2iufRsR8Vj7AdSFwZRNbKpb42jUGTViXJsTYrYkx15HjqOlUcZbKDylOi53ttNdhX0XsURQHpB4O/BvwZIrLqt+ZmZ8F1i/nW971vOUdj01nf+DAIccqSZJm0M9ZKs+qMI6ZrAYsy8z3lPd/ERFbUByv8dk5LPdDFEnMlIXAlXNYniRJmkWtL20eEZcDp2Tmbh3T9gQOyMyHDdpSmeZ1anmWiuVLafR839Vfnc+Qm8T9py2XNv8JsGnXtMdSnIoLxQGkVwNLph4sk4enAmeNIkBJkrRqda9wPBk4k+J4iy8DTwGOBf5vZp5QzrMU2A/YhSIB+SCwFbB5Zt7e4+vUssLRdp2fBKYM6xNBGz5lTMr1BOoUS1M0ZcyaEueg2r5+varioNGRy8z/jYiXUxxz8T6KhGKfqWSj9BFgTeBTFKfs/hjYsddkQ5IkVa/WCQdAZn4b+PYsjydFMvK+kQUlSZL6MuilzdemaG+sS9dxIJn5ueGENjp1b6nMVrazpKdhcn9aNceoP1WMl9tgdqMen8paKhHxYuAEYC2KC4B1ZiwJNC7hkCRJ1RrkLJXDgM8Aa2Xm2pn54I7bQ4YcnyRJaoG+WyoRcQuwZWZeUk1Io1f3lkqVLE1KkuaiyutwnAxsO2hgkiRp8gzycfY7wEcjYnPglxRfHX+vzPzmMALTcM1UyViw+gO47JAXjjO0xrEqNL0qr6sybk3Z5k2Jsy3GNd69vm7d9odBXv3Y8ud0p6EmMG/wcCRJUhv1nXBkZt0vhy5Jkmqm1pc2H5VJPmi0W91KcHXStLGpU7x1imUcmrL+k/5FZ3WLpymGeh2OiNgb+FRm3l7+PqPM/Pe+IpUkSa3Xa/r2doqLfd1e/j6TBEw4JEnSSmypYEtlNpYY22VV29Ptraq5j7VPldfhkCRJ6stAqWVEbAi8BNgIWL3zsczcdwhxSZKkFhnk0uZLgG8ClwCPAy4ANgYCOCcznz3kGCtnS0VqB8v10uhV2VL5EHBoZm5JcRDpK4GHA2cAXxlgeZIkqeUGqXDcBGydmRdHxPXA9pn5q4h4AvCNzNy4gjgrNewKh5+y1K37st/uF5I6Nfn/RpUVjlu477iNPwGbdDy2zgDLkyRJLTdICvVTYHvgQuC7wGERsSXwivIxSZKklQzSUnkUsFZmnh8RawKHAU8DLgL2zczLhx9mtUZ50Oh0ZbMml9Jm09b1Uv21fd9r+/qpWYZ6afMpETEP2BA4HyAzbwH2mEOckiRpAvR1DEdm3g18H3hwNeFIkqQ2GqSlsgxYmpmnVRPS6HkdjuGx1NscbqvxmvRvZh2Wtq5Xk1R5lsoBwKER8aKI+JuIWNR5GzRgSZLUXj1XOCLifRQHiN7UMbnzyQFkZs4bXnijYYWjfkbxqcVPRlI71e29Xbd4hq2Kg0YPBD4B/N0cY5MkSROmn4QjADLzjIpikSRJLdVPS+UeYL3MvLbakEZvFC2VtpfUNHruU/XlttEkqeQ6HMDvImLWDCUzH9LnMiVJUsv1m3AcCNxYRSCSJKm9+k04vpiZ11QSiVqh+1tRYfCSsmXp2S1Y/QFcdsgLxx2GpuG2aaaq/+ZM+t+0fq7D0d8VwiRJkkr9JBxRWRSSJKnV+r60eRvV9cJfdSu/1S0ezU1bt2db12uuJmFcJmEd66jKS5tLkiT1xQoH9a1wSGqHOn3yHmcsw3rtKtehTtuqKaxwSJKk2jDhkCRJlRuopRIRrwP2AB4JbJeZl0fEPsClmfmNIcdYOVsq42cZc3bd4wM4XlKfJvHvzCjWubKWSkTsCRwOfBdYG5j6OvobgH36D1WSJLXdIC2VvYDdM/Nfgbs7pi8DthxKVJIkqVX6bqlExG3A48o2yk3AEzLzkoh4DHB+Zj6oikCrZEvlPm0vObZ9/erAMVY394l2q/IslUuBraeZviNw4QDLkyRJLTdIhWM34P3AO4BPA7sBmwD7A7tl5heHHGPlrHDUh5+EVJVJ3LfqvM6jjK3O49AGlVU4MvM/gKXAwcAC4L+APYG3VZ1sRMR+EZERcWTHtDUi4uMR8eeIuDkiToyI9aqMQ5Ik9WeQs1QWZeYJmfkYYC1g/czcMDM/HRGPHn6I977uk4E3Aed3PXQE8GLg1cAOwAbA16qKQ5Ik9W+QlsqPgOdk5h1d0zcFTsvMDYcY39Sy1wLOAd4MHACcm5n7RMRi4FrgNZn51XLex1EcS7JdZv60x+W3uqXS5HJik2PvNop1adN4ScM07PeG77X7VHnQ6M3A1yPi3tGNiM2A04ETB1heLz4OfCczT+2a/iTggcC90zPzN8AfgO1mWlhEzI+IRVM3YGEFMUuSpNIgCccrgMXACVHYgiLZ+EJmvm2YwQFExM7ANhQHpXZbH7gzM2/omr68fGwm+wM3dtyuHEKokiRpBoNe2nxtiiTjIuCZwOcy813DDQ0i4uEUFxR7bmaeX047nftaKq8BjsvM+V3P+xnwg8xcOsNy5wOdz1kIXNnWloqk8bL8Pn7j3gbjeP1RvWavLZWeXr1sO3S6B9gJOIWijfLBqXlme7EBPAlYFzgnIqamzQOeGRFvBZ4HrB4Ra3dVOdYDrp5poeXxJ/ceg9KxbEmSVIFe050bgOlKIUHxJW5vKn9P7vtulWE4jftfLv044DfAh4ErgL8CSyiPHykPXt0IOGuIcUiSpDnoqaUSETv0usDMPGNOEa06ltMpWyrl/WOAFwC7AiuAj5VxPK2PZbb6LBWpDcZdEtdka9r+N8p4h9pSqTqJmKO3U7R4TqQ4LuNkitNnJUlSTfRa4dgKuCAz7yl/n9HUwZ1NUpcKRz8ZadOybU0e91H1o+37S5vXb6gVDuBcitNMryl/T4pjNroN+xgOSZLUAr0mHI+kuKLn1O+SJEk9G+g6HG1Tl5aKNKXN5dcpk7COVXHsVCfDbqmspDz1dC9gs3LShcDHMvO3gyxPkiS12yDfFvtK4AKKi3KdV962AS4oH5MkSVrJIN8WezFwQma+r2v6QcBrM3OTIcY3ErZUNBvL15I0syq/LfZvgM9NM/0/y8ckSZJWMkjCcTrwjGmmbw/8aE7RTKhb77yLjff7Dhvv9x1uvfOucYfTOo6vurlPSKM3SG34m8CHI+JJwE/LaX8LvBo4MCJeMjVjZn5z7iFKkqSmGyThOLr8+Wbufwnxozt+9yJgkiQJ8DocQL0PGvWAxeaqetvVbd+oWzwanum27SDbe5L3kTave5UHjUqSJPWl54QjIraLiBd1TXt9RFwaEddExKciYv7wQ5QkSU3Xc0slIr4HnJ6ZHy7vbwmcAxxPcaXRdwGfzMz3VxJphercUpE0d5PW3mojx7i+qmipbA2c1nF/Z+DszNw9Mw8H9gb+YZBgJUlSu/WTcDwYWN5xfwfgex33/xd4+DCCkiRJ7dJPS+Vy4HWZ+cOIWB24AXhxZp5WPr4lcEZmPqSyaCtiS6UeLJnWg9tBdTHovug+fJ9RjEUVLZXvAodExDOADwG3svKVRbcCLh4gVkmS1HL9VDjWAb5GcQnzm4FdMvPrHY+fBvw0M99bRaBVGkeFwwxcur9hvS98f6kp2rCv9lrh6HnNMvM64JkRsRi4OTPv7prl1RSJiCRJ0kr6TqUy88YZpv9l7uFIkqQ2al7tpiUWrP4ALjvkheMO437aUN6rguMyGnV9X+g+o3gvTNL7bZL2eS9tLkmSKmfCIUmSKue3xdK863BMUrlxrhyr9qtyG7v/9G9SxmxS1rMXflusJEmqDRMOSZJUOVsq1LOlYrnu/hwT1ZH7ZXu4LQdjS0WSJNWGFQ7qWeFoo0E+PdT1E0dd49J4tXm/aPO6DaIu41GHOKxwSJKk2jDhkCRJlbOlQv1bKnUomal/M203t2f9uE00DJO6H9lSkSRJtWHCIUmSKmdLhXq2VJpSmmtKnN2aGncbTeK3j9Ytnrbqd5ybsl3qFqctFUmSVBtWOKhnhUOzq1uGX1dNGafuOIHaxd2UsWyyto/xsNavbuNkhUOSJNWGCYckSaqcLRVsqaje6lY+bbu2Hmg4qdw+1bOlIkmSasOEQ5IkVa7WLZWI2B94BfA44DbgTGBpZv62Y541gMOAnYH5wMnAmzNzeR+v08iWiqXC9mvCNm5CjOqP21T9aEtLZQfg48DfAs8FHgh8PyLW7JjnCODFwKvL+TcAvjbiOCVJ0ixqnbZm5o6d9yNiV+Aa4EnADyNiMfBG4DWZ+T/lPG8ALoyIv83Mn444ZEmSNI1at1S6RcSjgYuALTPzgoh4NnAa8ODMvKFjvsuBIzPziBmWM5+i/TJlIXBl01oqdVF1+XXQ5c8lLkvKqgv3RdVdW1oq94qI1YAjgZ9k5gXl5PWBOzuTjdLy8rGZ7A/c2HG7csjhSpKkDo2pcETEMcDzge0z88py2muA4zJzfte8PwN+kJlLZ1iWFY4x8JOapFGb7e+Of5OGo9cKRyNGNyKOAl4EPHMq2ShdDaweEWt3VTnWKx+bVmbeAdzRsfwhRyxJkjrVuqUShaOAlwPPzsxLu2b5OfBXYEnHczYFNgLOGlmgkiRpVrVuqUTE0cBrgJcCv+146MbMvK2c5xjgBcCuwArgYwCZ+bQ+Xmeo1+HopUxnKU/9ato+M454mzZGGr6m7gNNjRva01LZs/x5etf0NwDHl7+/HbgHOJGOC3+NIDZJktSjWiccmbnKgysy83bgLeVNkiTVUK1bKqPS1EubS6PQWeqd0rSS7yg0uSQuzUXrrsMhSZKaywoH9apw1PFTUh1j6jRTfHWPW5I6VfE3axR/B61wSJKk2jDhkCRJlbOlQr1aKqNky2HyTNI2n+u69vP8fl9rkrbDIJowPk2IcVRsqUiSpNow4ZAkSZWzpcLktlSkKlhqnt6qxqVN4zbudRn36w9iFDFX9Rq2VCRJUm2YcEiSpMrZUsGWyjDMVqprYnlT4+P+cp+2jEVb1kPTs6UiSZJqwwoHVjjk5dElaVBWOCRJUm2YcEiSpMrZUqH5LZVhlP1tHYyX4z88jmU9uB2qU7extaUiSZJqw4RDkiRVzpYKzW+pDKpuZTlNplG1BNu2v7dtfdRctlQkSVJtWOFgciscVfMTWPO4zTQT943BTMK4WeGQJEm1YcIhSZIqZ0sFWyrSXNWxbFzHmKQ2sqUiSZJqw4RDkiRVzpYKtlTmytK11Cyd71lo9/vWv0/Vs6UiSZJqw4RDkiRVzpYKtlSaxPLo3Dh+qiP3y2azpSJJkmrDNFKNsmD1B3DZIS8c6WtO9+mrrp/I6hrXJBjl2LdtO4/jfV1nc9m+dd43rHBIkqTKmXBIkqTKedAoHjQqqbmGWULvXNayA5aw7cGnDWW5qt44WykeNCpJkmrDhEOSJFXOlgrtb6nU+ahlqH98koajze/1Nq/bqthSkSRJtWGFg+ZXOLq/iAnqf72IUWv6ODQh/ibEWKVJXf9JXe8qNHUsrXBIklLfKtQAAAr4SURBVKTaMOGQJEmVa01LJSLeArwLWB84D9grM3/W43OH2lJp0qWwpTbo5f3le1CqxkS1VCJiJ+Bw4CBgG4qE4+SIWHesgUmSJKAlCQewL3BsZh6Xmb8G9gBuBf55vGFJkiRoQUslIlanSC5elZkndUz/LLB2Zr50mufMB+Z3TFoIXDnss1SaVsIdRbzX3Xz7vZdLXnbAEtZZa41pX39KZxx1G8+6xdMEfqPq9Ooc6zhjq/O49KtN69Jtkloq6wDzgOVd05dTHM8xnf2BGztuV1YWnSRJakXCMYgPAYs7bhuONxxJktptIlsq0yyj0Rf+kiRpXCampZKZdwI/B5ZMTYuI1cr7Z40rLkmSdJ+2HLVyOPDZiFgG/AzYB1gTOG6sUUmSJKAlCUdmfikiHgp8gOJA0XOBHTOz+0BSSZI0Bq1IOAAy8yjgqHHHIUmS7q/xx3BIkqT6M+GQJEmVM+GQJEmVM+GQJEmVM+GQJEmVM+GQJEmVM+GQJEmVM+GQJEmVM+GQJEmVa82VRodhxYoZv+ROkiRNo9f/nY3/evphiIiHAVeOOw5Jkhpsw8z840wPmnAAERHABsBNQ1zsQookZsMhL3dSOZ7D55gOn2M6fI7p8FUxpguBq3KWpMKWClAO0IxZ2SCKHAaAmzLTXs0cOZ7D55gOn2M6fI7p8FU0pqtcjgeNSpKkyplwSJKkyplwVOcO4KDyp+bO8Rw+x3T4HNPhc0yHbyxj6kGjkiSpclY4JElS5Uw4JElS5Uw4JElS5Uw4JElS5Uw45iAi3hIRl0XE7RFxdkQ8ZRXzvzoiflPO/8uIeMGoYm2CfsYzIh4fESeW82dE7DPKWJuizzHdPSJ+FBHXl7dTV7VPT6I+x/QVEbEsIm6IiFsi4tyIeN0o422Cfv+Wdjxv5/L9f1LVMTZJn/voruUYdt5uryIuE44BRcROwOEUpxZtA5wHnBwR684w/9OALwCfBp4InAScFBFbjCbieut3PIEFwCXAfsDVIwmyYQYY02dR7KN/B2wHXAF8v/yuITHQmP4F+FeK8dwKOA44LiKeN4JwG2GAMZ163sbAocCPKg6xUQYczxXA33TcHlFJcJnpbYAbcDZwVMf91Sguj77fDPN/Cfh217SfAp8Y97rU4dbveHY99zJgn3GvQ91ucxnTcv555R+i1497Xepym+uYls85B/jguNelLrdBxrTcN38CvBE4Hjhp3OtRl9sA/5t2BW4YRWxWOAYQEasDTwJOnZqWmfeU97eb4Wnbdc5fOnmW+SfGgOOpWQxpTBcAD6T4lD7x5jqmUVgCbAr8sKo4m2QOY/o+4JrM/HS1ETbLHMZzrYi4PCKuiIhvRMTjq4jPhGMw61Bk2Mu7pi8H1p/hOev3Of8kGWQ8NbthjOmHgau4f6I8qQYa04hYHBE3A3cC3wH2ysxTKouyWfoe04jYnqKysXu1oTXSIPvob4F/Bl4KvJYiLzgzIjYcdnB+W6yk+4mI/YCdgWdlZiUHkE2Qm4CtgbWAJcDhEXFJZp4+1qgaKCIWAp8Hds/M68YdTxtk5lnAWVP3I+JM4ELgTcC/DPO1TDgGcx1wN7Be1/T1mPkAxqv7nH+SDDKemt3AYxoR76Q4GPc5mXl+NeE10kBjWpa0f1/ePTciNgP2B06vIMam6XdMNwE2Br7V8RXrqwFExF3Appl5cSWRNsOc/5Zm5l8j4hfAo4ccmy2VQWTmncDPKT6tABARq5X3z5rhaWd1zl967izzT4wBx1OzGHRMI+LdFJ9qdszMZVXH2SRD3E9XA+YPN7pmGmBMfwNsSVExmrp9E/hB+fsVFYdca8PYRyNiHsUY/6mKAL0NdiTwTsDtwC7AZsAngeuB9crHPwd8qGP+pwF/Bd4BPA54P0VPd4txr0sdbgOM5+rc9wfnKuCj5e+PHve61OU2wJgupfj2yFdS9HunbmuNe13qchtgTPen+GDxqHL+d5R/B3Yb97rU5dbvmE7z/OPxLJWBx5PiANy/L/fRbShOjb8N2HzYsdlSGVBmfikiHgp8gOKP8rkUnwqnDtbZCLinY/4zI+I1wMHAvwEXAS/LzAtGG3k99TuewAbALzruv7O8nUFxPYmJN8CY7kmRyH21a1EHUSTIE2+AMV0TOBrYkOKP+G+A12bml0YXdb0NMKaaxQDj+WDg2HLe6ykqJE/LzF8POza/nl6SJFXOYzgkSVLlTDgkSVLlTDgkSVLlTDgkSVLlTDgkSVLlTDgkSVLlTDgkSVLlTDgkSVLlTDgk3U9EHB8RJ43x9T8fEe/puH9ZROwzrnhWJSIOiYiPjTsOqc680qg0YSJiVW/6g4AjKP4+3DCCkFYSEU8A/gd4RGbeXE57KHBLZt466nh6ERHrAJcAW2fmJeOOR6ojEw5pwkTE+h13d6L4zoVNO6bdPPWPfhwi4j+AuzJzj3HFMIiI+ApwWWa+a9yxSHVkS0WaMJl59dQNuLGYdN+0zLy5u6USEadHxMci4siIuD4ilkfE7hGxZkQcFxE3RcTvI+L5na8VEVtExPci4ubyOZ8vqwHTKr8a+1XAt7qmr9RSiYiMiN0i4usRcWtEXBQRL5ltvSPizeV8t5exfLXjsdUiYv+IuDQibouI8yLiVV3Pf3xEfDsiVpTr+6OI2KRjlm8BO88WgzTJTDgk9WoX4DrgKcDHgGOArwBnUnyt9feBz0fEAoCIWJuiNfILYFtgR2A94MuzvMZWwGJgWQ/xHFguayvgu8AJEfGQ6WaMiG2Bf6f4Ku5Ny1h+2DHL/sDrgT2Ax1O0lP4zInYon/+wcv47gGcDTwI+Ayt94/bPgA0jYuMeYpcmjl9PL6lX52XmwQAR8SFgP+C6zDy2nPYBiq+43wr4KfBW4BeZ2Xnw5z8DV0TEYzPzd9O8xiOAu4Freojn+Mz8Qrnc9wB7UyRD/z3NvBsBtwDfzsybgMspEiEiYj7wHuA5mXlWOf8lEbE98CbgDOAtFNWgnTPzr+U83fFf1bEOl/UQvzRRTDgk9er8qV8y8+6I+DPwy47Hl5c/1y1/PgH4u4iY7niQTbj/P2yABwF3ZG8Hl3XGc0tErOh47W6nUCQZl0TEf1MkJV8vD0J9NLAAOCUiOp+zOmVSAmwN/Kgj2ZjObeXPBT3ELk0cEw5Jver+Z5ud0zIzy3/YU63atSiOa1g6zbL+NMNrXAcsiIjVM/POAeKZtk2cmTdFxDbAs4C/pzhQ9v0R8eQyToAXAn/seuod5c/bWLWpds61PcwrTRwTDklVOQd4JcWZG3f1+Jxzy5+bd/w+FGUMpwKnRsRBwA0Ux2OcQpFYbJSZZ8zw9POBXSLigbNUObagSIJ+Ncy4pbbwoFFJVfk4xaf+L0TEkyNik4h4XnlWy7zpnpCZ11IkKtsPM5CIeFFE7B0RW0fEIygOEF0N+G15TMehwBERsUsZ5zYRsVdE7FIu4ihgEfDFiNg2Ih4TEa+LiM7TiZ9B0XbppRoiTRwTDkmVyMyrgKcD8yjOYPklcCRFZeGeWZ76H8A/DTmcG4BXUJw1cyHF2Sj/mJlT1Yh/AT5IcbbKhRTHeLwQuLRclz9TVEPWojiI9OfA7qzc1tkZOHbIcUut4YW/JNVKRDwI+C2wU8dZI7VWXn/kMGCrPtpH0kSxwiGpVsqWxOuBGS8QVkNrAm8w2ZBmZoVDkiRVzgqHJEmqnAmHJEmqnAmHJEmqnAmHJEmqnAmHJEmqnAmHJEmqnAmHJEmqnAmHJEmqnAmHJEmq3P8HFAVCT5EAtZcAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 600x400 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}